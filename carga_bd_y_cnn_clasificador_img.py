# -*- coding: utf-8 -*-
"""Carga_BD_y_CNN_clasificador_Img.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SZ205kApAnEy8LX8vXl3ObRoXSwybswo

## CARGA DE BASE DE DATOS
"""

import os
import zipfile

"""### Descarga de archivo .zip de Google cloud store y se almacena en archivos temporales tmp"""

!wget --no-check-certificate https://storage.googleapis.com/platzi-tf2/databasesLoadData.zip \
    -O /tmp/databasesLoadData.zip

# Descomprimimos archivo .
local_zip = '/tmp/databasesLoadData.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp/databasesLoadData')
zip_ref.close()

# Commented out IPython magic to ensure Python compatibility.
import json
import codecs
import requests
import numpy as np
from PIL import Image
from io import BytesIO
# %matplotlib inline
import matplotlib.pyplot as plt

"""### Extraccion de data .json

"""

url_json = "/tmp/databasesLoadData/sign_mnist_json/data.json"

"""### Contenido del archivo .json
{"content": "https://storage.googleapis.com/platzi-tf2/img_mnist/29_B.jpg","label":"b"} x5

"""

# Deserealizar json
data_json = [] # Guardamos los registros o lineas en la lista
with codecs.open(url_json, 'r','utf-8') as js: # abrimos el archivo con codificacion utf-8,'r' modo lectura
# donde js nombre de la variable de referencia delarchivo abierto
  for line in js:
    data_json.append(json.loads(line))


print("{} imagenes encontradas".format(len(data_json)) )

"""### Extraccion de imagenes"""

images = [] # lista que guarda las imagenes y el label

for data in data_json:
  response = requests.get(data['content']) # obtenemos la imagen codificada
  img = np.asarray(Image.open(BytesIO(response.content))) # decodificacion de la imagen y la comvetimos en un array
  #response.content = response.content obtiene el contenido binario de la respuesta HTTP (en este caso, la imagen descargada). Este contenido es una secuencia de bytes que representa la imagen.
  #BytesIO() BytesIO(response.content) crea un "archivo virtual en memoria" a partir de esos bytes. Es como si tuvi√©ramos el archivo de la imagen en lugar de tenerlo en el disco.
  #Image.open() abre el archivo de imagen. En este caso, en lugar de abrir un archivo desde el sistema de archivos, le pasamos el archivo en memoria creado con BytesIO.
  images.append([img, data["label"]])

plt.imshow(images[0][0])
print(images[0][1])

"""### Cargar base64



"""

import base64

url = "/tmp/databasesLoadData/sign_mnist_base64/data.json"

"""contenido del archivo
{"b": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/AOhS246VBdyJbqyDmbaGVSOuWxTUk3XckDKcGVkjI/2VBOf1qcwc9K00i4rnNbCLrcSPMkQKJ97PUNnHHtmrllEf7US3dSJIEklcEdd7DBHtjP5VrGLmrSpxWHewQnxNHNOBsAJOfYZpvh8zXup394xPkKBAg9SDk/lx+db5j5pCcICO+K47X7+cL5uRv2kZxXW6TaRWek20UIIBQOSepZhkk/iasMxDV//Z"}

"""

# Obtener el contenido del archivo

with open(url) as f :
  data = json.load(f)

print(data)
print(type(data))

base64_img_bytes = data['b'].encode('utf-8') # conversion (codificacion)de string en bytes
path_img = "/tmp/decoded_images.png" # ruta donde quedara almacenada la imagen
with open(path_img, "wb") as file_to_save: # cracion de objeto de referencia con permiso de escritura
  decoded_image_data = base64.decodebytes(base64_img_bytes) # decodificacion de binarios a bytes (pixeles de 1 -255)
  file_to_save.write(decoded_image_data)# escribe la imagen en la ruta indicada

img = Image.open(path_img)
img

"""### Las imagenes no son mas que una matriz de n x m de numeros del 1-255"""

img = Image.open("/tmp/databasesLoadData/pixeles.png")
img

"""### lectura de csv"""

import pandas as pd

train = pd.read_csv("/tmp/databasesLoadData/sign_mnist_train/sign_mnist_train.csv")
test = pd.read_csv("/tmp/databasesLoadData/sign_mnist_test/sign_mnist_test.csv")

# 785 columnas ya que las imagenes son de 28 x 28 y las filas son el numero de imagenes
train.head()

train.shape

# guardamos los labels
labels = train['label'].values

# borramos el target label del df de entrenamiento

train.drop('label',axis=1,inplace=True)

# visualizamos la primera imagen de nuestro df
plt.imshow(train.values[1].reshape(28,28))
print(labels[1])

"""# Procesamiento de datos , visualizacion de la data

### Obtenemos data del archivo train_clean y vemos si estan balanceadas las clases
"""

train = pd.read_csv("/tmp/databasesLoadData/sign_mnist_train/sign_mnist_train_clean.csv")

import seaborn as sns

# Vemos cuantos tipos de labels hay
unique_val = np.array(train['label'].unique())

unique_val

plt.figure(figsize = (10, 10))
sns.set_style("darkgrid")
sns.countplot(data=train,x='label',palette="Set2")

"""podemos observar que si estan balanceadas las cargas de cada clase"""

# Vemos si existen nulos

train.isnull().values.any()

# vemos si hay duplicados

train[train.duplicated()]

# vemos que hay 4 duplicaciones por lo tanto guardamos sus indces en una lista y los eliminamos

duplicated_rows = train[train.duplicated()].index
train = train.drop(duplicated_rows)

duplicated_rows

# verificamos si aun quedan columnas con texto

train[train['pixel4']=='fwefew']

# borramos el elemento faltante
train = train.drop(727,axis=0)

"""# Normalizacion"""

train.dtypes

# convetimos a float las columnas
train = train.astype('float32')

test = test.astype('float32')

train = train.astype('float32')

y_train = train['label']
#y_test = test['label']
del train['label']
#del test['label']

# ahora dividimos cada pixel entre 255 para que nos queden valores de 0 - 1
train = train / 255
#test = test / 255

train.shape

"""# Creacion del modelo"""

import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense ,BatchNormalization,ReLU,Input
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras import models, optimizers, regularizers

# convertimos los dataframes train y tes a arrays numpy
train_np = train.to_numpy()
#test_np = test.to_numpy()

train_images = train_np.reshape(train_np.shape[0], 28, 28, 1) # El 1 al final es el canal del color
#test_images = test_np.reshape(test_np.shape[0], 28, 28, 1)

train_images.shape

# cambiamos el label de tipo escalar a un arrebglo binario
y_train[0]

y_train = tf.keras.utils.to_categorical(y_train, 25)
#y_test = tf.keras.utils.to_categorical(y_test, 25)

"""# Creacion del modelo"""

def model1 ():

  model = models.Sequential([
          Input(shape=(28,28,1)),

          Conv2D(32,(3,3),padding='same'),
          BatchNormalization(),
          ReLU(),
          MaxPooling2D((2,2)),
          Dropout(0.2),

          Conv2D(64,(3,3),padding='same'),
          BatchNormalization(),
          ReLU(),
          MaxPooling2D((2,2)),
          Dropout(0.4),

          Conv2D(128,(3,3),padding='same'),
          BatchNormalization(),
          ReLU(),
          MaxPooling2D((2,2)),
          Dropout(0.5),

          Flatten(),
          Dense(256,activation='relu'),
          Dropout(0.5),
          Dense(25,activation='softmax')

          ])

  return model

"""## Callbacks"""

checkpoint = ModelCheckpoint('optmizador.keras',monitor='val_accuracy', verbose= 1, save_best_only=True)

# compilacin
model = model1()
model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

train_images.shape

# separamos entrenamioento y validacion
x_train = train_images[:20000]
x_val = train_images[20000:]
y_train_1 = y_train[:20000]
y_val = y_train[20000:]

y_train.shape

## Entrenando el modelo"""

hist = model.fit(x_train, y_train_1,
                  batch_size=32,
                epochs=100,
                validation_data=(x_val,y_val),
                 verbose=1,
                 callbacks=[checkpoint])

import matplotlib.pyplot as plt

plt.plot(hist.history['accuracy'], label = 'Train')
plt.plot(hist.history['val_accuracy'], label = 'Val')
plt.legend()
plt.show()

type(hist.history['accuracy'])

from sklearn.model_selection import KFold

# Tranformamos la data de train y test a dataframes
x_train_df = pd.DataFrame(train_images)
x_test_df = pd.DataFrame(test)

y_train_df = pd.DataFrame(y_train)
y_test_df = pd.DataFrame(y_test)

# hacemos un k-fold validation
# Inicializar KFold
kf = KFold(n_splits=4)

#Listas que almacenan el mae y r2
accuracy = []
val_accuracy = []
# Ciclo de  cross-validation
for train_index, test_index in kf.split(train_images):
    X_train_fold, X_test_fold = train_images.iloc[train_index], x_train.iloc[test_index]#train_index lista de indices de set de entrenamiento
    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]



   # Entrenamiento del modelo con el set de entrenamiento
    history = model.fit(X_train_fold, y_train_fold, epochs=100, batch_size =32,
                        validation_data = (X_test_fold, y_test_fold),
                        verbose=0)


    # Calcular y almacenar accuracy
    accuracy.extend(hist.history['accuracy'])

    #Calcular y almacenar val_accuracy
    val_accuracy.extend(hist.history['val_accuracy'])