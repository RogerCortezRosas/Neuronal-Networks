# -*- coding: utf-8 -*-
"""Clasificacion_Multiple.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UNTSmSuaI-dYxr-l7MCvjgD0oHxLUiWg

Data set de noticias en donde se clasificacan en 46 tipo de temas
"""

from keras.datasets import reuters
from keras import layers, models
import numpy as np

"""# Descarga de datos"""

(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)

"""# Diccionario de palabras"""

word_index = reuters.get_word_index()
word_index = dict([(value,key) for (key,value) in word_index.items()])

for _ in train_data[0]:
    print(word_index.get( _ - 3))

# Train data es de tipo vector y no tensor(matriz ) por lo cual es necesario convertirlo
train_data.shape

"""# Funcion de vectorizar"""

def vectorizar(sequences, dim=10000):
    results = np.zeros((len(sequences),dim))
    for i, sequences in enumerate(sequences):
        results[i,sequences]=1
    return results

x_train = vectorizar(train_data)
x_test = vectorizar(test_data)

# en train_labes pasa que son datos escalares lo cual hay que convertirlo
train_labels[0]

from tensorflow.keras.utils import to_categorical

y_train = to_categorical(train_labels)
y_test = to_categorical(test_labels)

y_train[0]

"""# Creamos el modelo"""

model = models.Sequential()
model.add(layers.Dense(64,activation='relu',input_shape=(10000,)))
model.add(layers.Dense(64,activation='relu'))
model.add(layers.Dense(46,activation='softmax'))# softmax es mas factible para clasificacion multiple

model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['acc']
             )

x_val = x_train[:1000]
partial_x_train = x_train[1000:]

y_val = y_train[:1000]
partial_y_train =  y_train[1000:]

"""# Entrenando el modelo"""

history = model.fit(partial_x_train,
                   partial_y_train,
                   epochs=9,
                   batch_size=512,
                   validation_data=(x_val,y_val))

"""# Validacion de resultados"""

import matplotlib.pyplot as plt

history_dict = history.history
loss_values = history_dict['loss']
val_loss_values = history_dict['val_loss']

fig = plt.figure(figsize=(10,10))
epoch = range(1,len(loss_values)+1)
plt.plot(epoch,loss_values, 'o',label='training')
plt.plot(epoch,val_loss_values, '--',label='val')
plt.title('Grafica de funcion de perdida en el lote de validacion y de entrenamiento')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

history.history.keys()

import matplotlib.pyplot as plt

history_dict = history.history
loss_values = history_dict['acc']
val_loss_values = history_dict['val_acc']

fig = plt.figure(figsize=(10,10))
epoch = range(1,len(loss_values)+1)
plt.plot(epoch,loss_values, 'o',label='training')
plt.plot(epoch,val_loss_values, '--',label='val')
plt.title('Grafica de accuaracy en el lote de validacion y de entrenamiento')
plt.xlabel('Epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()

"""# Hcemos las predicciones"""

model.evaluate(x_test, y_test)

predictions = model.predict(x_test)

predictions[0] # Son los 46 posibles valores con diferentes probabilidades cada uno se obtine el de mayotr probabilidad

np.argmax(predictions[0])# Obteniendo el dato con mayor valor

"""# Mejoramos el modelo con regularizaciones"""

model2 = models.Sequential()
model2.add(layers.Dense(64,activation='relu',input_shape=(10000,)))
model2.add(layers.Dropout(0.5))# para que desactive el 50 % de las neuronas
model2.add(layers.Dense(74,activation='relu'))
model2.add(layers.Dropout(0.5))# para que desactive el 50 % de las neuronas
model2.add(layers.Dense(46,activation='softmax'))# softmax es mas factible para clasificacion multiple

model2.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['acc']
             )

history2 = model2.fit(partial_x_train,
                   partial_y_train,
                   epochs=15,
                   batch_size=512,
                   validation_data=(x_val,y_val))

import matplotlib.pyplot as plt

history_dict = history2.history
loss_values = history_dict['loss']
val_loss_values = history_dict['val_loss']

fig = plt.figure(figsize=(10,10))
epoch = range(1,len(loss_values)+1)
plt.plot(epoch,loss_values, 'o',label='training')
plt.plot(epoch,val_loss_values, '--',label='val')
plt.title('Grafica de funcion de perdida en el lote de validacion y de entrenamiento')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

import matplotlib.pyplot as plt

history_dict = history2.history
loss_values = history_dict['acc']
val_loss_values = history_dict['val_acc']

fig = plt.figure(figsize=(10,10))
epoch = range(1,len(loss_values)+1)
plt.plot(epoch,loss_values, 'o',label='training')
plt.plot(epoch,val_loss_values, '--',label='val')
plt.title('Grafica de accuaracy en el lote de validacion y de entrenamiento')
plt.xlabel('Epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()

# Accuracy
modelo1 = model.evaluate(x_test, y_test)
modelo2 = model2.evaluate(x_test, y_test)

print('Accuracy modelo 1',modelo1[1])
print('Accuracy modelo 2',modelo2[1])